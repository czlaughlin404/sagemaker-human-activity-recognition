{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49cba081",
   "metadata": {},
   "source": [
    "# Step 1\n",
    "Carry over the S3 bucket stored from the first notebook and import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b9238f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sagemaker\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "%store -r\n",
    "print ('data_bucket_name=',data_bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a74d7df",
   "metadata": {},
   "source": [
    "# Step 2\n",
    "Establish a SageMaker Training job name, these must be unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5fa1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name='har-tf-'+time.strftime('%Y-%m-%d-%H-%M-%S')\n",
    "print(job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0a94f9",
   "metadata": {},
   "source": [
    "# Step 3\n",
    "These settings work as is for demonstration purposes.  Setting the epochs to a higher number can yield better results.  Each epoch here, with this dataset (w=128, s=32 from prior notebook) on a ml.m5.large take approximately 40 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6956d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_json={\n",
    "    'epochs': 5,\n",
    "    'batch_size': 64}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179d0ad8",
   "metadata": {},
   "source": [
    "# Step 4 Define the Tensorflow Environment\n",
    "Create a tensorflow estimator.  As delivered, this will create one instance of a ml.m5.large.  This will also automatically push the entry script to S3.  Consult the link for more options such as specifing a fixed entry point script or training from a prior model save point, instead of starting training from a naive position.\n",
    "\n",
    "https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40544020",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tf_estimator = TensorFlow(use_spot_instances=False,\n",
    "                          enable_sagemaker_metrics=True,\n",
    "                          entry_point='train_tf.py', \n",
    "                          #model_uri='s3://bucket/folder/output/model.tar.gz',\n",
    "                          role=role,\n",
    "                          instance_count=1, \n",
    "                          instance_type='ml.m5.large',\n",
    "                          framework_version='1.12', \n",
    "                          volume_size=8,\n",
    "                          py_version='py3',\n",
    "                          script_mode=True,\n",
    "                          hyperparameters=hyperparameter_json\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e0b9fa",
   "metadata": {},
   "source": [
    "# Step 5 Start a Tensorflow Training Job\n",
    "This step will initiate a SageMaker Training job.  Note the parameter of wait=True.  This will cause this notebook to wait on the training job to complete.  In a production scenario, this step would NOT wait, but would be a single step in a state machine.  This step can take about 5-7 minutes to complete, as delivered.  Factors such as epoch or other changes can effect runtime.\n",
    "\n",
    "https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html#sagemaker.estimator.EstimatorBase.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1903e7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf_estimator.fit(\n",
    "    inputs={\n",
    "    'training': 's3://'+data_bucket_name+'/train',\n",
    "    'test': 's3://'+data_bucket_name+'/test'\n",
    "    },\n",
    "    wait=True,\n",
    "    job_name=job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16c65d6",
   "metadata": {},
   "source": [
    "# Step 6\n",
    "This step will loop, waiting on the training job to complete, in a case when the prior fit() step specified wait=False.\n",
    "\n",
    "https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeTrainingJob.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54d41f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "client = boto3.client('sagemaker')\n",
    "\n",
    "response = client.describe_training_job(\n",
    "    TrainingJobName=job_name\n",
    ")\n",
    "\n",
    "while (response['TrainingJobStatus'] not in ('Failed','Completed','Stopped','Stopping','Interrupted','MaxRuntimeExceeded')):\n",
    "    print (response['TrainingJobStatus'])\n",
    "    time.sleep(15)\n",
    "    response = client.describe_training_job(TrainingJobName=job_name)\n",
    "    \n",
    "print('job_name=',job_name)\n",
    "print('TrainingTimeInSeconds=',response['TrainingTimeInSeconds'])\n",
    "print('TrainingJobStatus=',response['TrainingJobStatus'])\n",
    "print('S3ModelArtifacts=',response['ModelArtifacts']['S3ModelArtifacts'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f64c7cc",
   "metadata": {},
   "source": [
    "# Step 7 Deploy Trained Model to an API Endpoint\n",
    "When the training job is complete, harvest the model S3 location from the prior step and supply it as a parameter here.  This step deploys an API endpoint that serves model inference real-time.  This step can take about 5-7 minutes to complete.  Note the parameter of wait=True.  This will cause this notebook to wait on the API endpoint deployment to complete.  In a production scenario, this step would NOT wait, but would be a single step in a state machine.  \n",
    "\n",
    "https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/deploying_tensorflow_serving.html#deploying-directly-from-model-artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9b7096",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlowModel\n",
    "tf_endpoint_name = 'ep-'+job_name\n",
    "\n",
    "model_artifact = response['ModelArtifacts']['S3ModelArtifacts']\n",
    "\n",
    "model = TensorFlowModel(model_data=model_artifact, role=role, framework_version='1.12')\n",
    "                                       \n",
    "predictor = model.deploy(initial_instance_count=1, \n",
    "                         instance_type='ml.t2.medium',\n",
    "                         endpoint_name=tf_endpoint_name,\n",
    "                         #accelerator_type='ml.eia1.medium'\n",
    "                         wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2548f144",
   "metadata": {},
   "source": [
    "# Step 8\n",
    "This step waits for the endpoint to become In-Service.  The response is printed for observability.  The endpoint name is captured as a variable and will be passed to the third notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3f4d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import pprint\n",
    "client = boto3.client('sagemaker')\n",
    "\n",
    "response = client.describe_endpoint(\n",
    "    EndpointName=tf_endpoint_name\n",
    ")\n",
    "\n",
    "while (response['EndpointStatus'] not in ('InService')):\n",
    "    time.sleep(15)\n",
    "    response = client.describe_endpoint(\n",
    "    EndpointName=tf_endpoint_name)\n",
    "    print(response['EndpointStatus'])\n",
    "    \n",
    "pprint.pprint(response)\n",
    "print('tf_endpoint_name=',tf_endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed26ec0",
   "metadata": {},
   "source": [
    "# Step 9\n",
    "Pass variables to next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62bc2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store tf_endpoint_name\n",
    "%store data_bucket_name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
