{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e44f808",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "Prerequisite: check the upper right hand corner of the UI to make sure your notebook kernel is conda_tensorflow2_p36\n",
    "\n",
    "We start by:\n",
    "- Specify your S3 bucket name from the Stack Create section in CloudFormation.\n",
    "- Importing various Python libraries we'll need S3 bucket to upload shaped data\n",
    "\n",
    "Run cells by clicking either (1) the play symbol that appears to the left of In[] when you hover over it, or (2) the 'Run cell' button in the toolbar above, or (3) using Control + Enter from your keyboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c36242e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import save\n",
    "import boto3 \n",
    "import os\n",
    "\n",
    "data_bucket_name='YOUR-BUCKET-HERE'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a805c5af",
   "metadata": {},
   "source": [
    "# Step 1\n",
    "Import CSV from your notebook into a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d2c262",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ts = pd.read_csv('data/train_ts.csv')\n",
    "test_ts = pd.read_csv('data/test_ts.csv')\n",
    "\n",
    "train_ts = train_ts.drop(['Unnamed: 0'], axis=1)\n",
    "test_ts = test_ts.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde37643",
   "metadata": {},
   "source": [
    "# Step 1b\n",
    "Use the next cell to view data for one participant\n",
    "Activity Classes\n",
    "0=downstairs; 1=upstairs; 2=walking; 3=jogging; 4=standing; 5=sitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32888e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = train_ts[train_ts['act']==3]\n",
    "subset = subset[subset['id']==0]\n",
    "subset.plot(subplots=True,figsize = (20,30))\n",
    "subset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac1bd15",
   "metadata": {},
   "source": [
    "# Step 2\n",
    "Timeseries to seconds (ts_to_secs) is a function that reshapes the Pandas data frame in prior step into a n-dimensional numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f56a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_to_secs(dataset, w, s):\n",
    "    \n",
    "    data = dataset[dataset.columns[:-3]].values    \n",
    "    act_labels = dataset[\"act\"].values\n",
    "    id_labels = dataset[\"id\"].values\n",
    "    trial_labels = dataset[\"trial\"].values\n",
    "\n",
    "    ## We want the Rows of matrices show each Feature and the Columns show time points.\n",
    "    data = data.T\n",
    "\n",
    "    m = data.shape[0]   # Data Dimension \n",
    "    ttp = data.shape[1] # Total Time Points\n",
    "    number_of_secs = int(round(((ttp - w)/s)))\n",
    "\n",
    "    ##  Create a 3D matrix for Storing Sections  \n",
    "    secs_data = np.zeros((number_of_secs , m , w ))\n",
    "    act_secs_labels = np.zeros(number_of_secs)\n",
    "    id_secs_labels = np.zeros(number_of_secs)\n",
    "\n",
    "    k=0\n",
    "    for i in range(0 , ttp-w, s):\n",
    "        j = i // s\n",
    "        if j >= number_of_secs:\n",
    "            break\n",
    "        if id_labels[i] != id_labels[i+w-1]: \n",
    "            continue\n",
    "        if act_labels[i] != act_labels[i+w-1]: \n",
    "            continue\n",
    "        if trial_labels[i] != trial_labels[i+w-1]:\n",
    "            continue\n",
    "            \n",
    "        secs_data[k] = data[:, i:i+w]\n",
    "        act_secs_labels[k] = act_labels[i].astype(int)\n",
    "        id_secs_labels[k] = id_labels[i].astype(int)\n",
    "        k = k+1\n",
    "        \n",
    "    secs_data = secs_data[0:k]\n",
    "    act_secs_labels = act_secs_labels[0:k]\n",
    "    id_secs_labels = id_secs_labels[0:k]\n",
    "    return secs_data, act_secs_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4af895",
   "metadata": {},
   "source": [
    "# Step 3\n",
    "This cell works as is.  You may change the w and s parameters.  w indicates how many time-series steps to retain for training.  The data is captured at 50 Hz (samples per second); therefore w=128 is about ~2.5 seconds of observation.  The step size divides the 128 into smaller steps of N.  Note here 128 is a multiple of 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3767acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This Variable Defines the Size of Sliding Window\n",
    "## ( e.g. 100 means in each snapshot we just consider 100 consecutive observations of each sensor) \n",
    "w = 128 # 50 Equals to 1 second for MotionSense Dataset (it is on 50Hz samplig rate)\n",
    "## Here We Choose Step Size for Building Diffrent Snapshots from Time-Series Data\n",
    "## ( smaller step size will increase the amount of the instances and higher computational cost may be incurred )\n",
    "s = 32\n",
    "train_data, act_train = ts_to_secs(train_ts.copy(), w, s)\n",
    "\n",
    "s = 32\n",
    "test_data, act_test = ts_to_secs(test_ts.copy(), w, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd50fac",
   "metadata": {},
   "source": [
    "# Step 4\n",
    "Convert the activity train and set labels into a one-hot encoded array.  Natively the domain of values are 0-5 and serve as a class label.  This allows the predictions to have a probability by class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcff3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "act_train_labels = to_categorical(act_train)\n",
    "act_test_labels = to_categorical(act_test)\n",
    "    \n",
    "## 3 dimensions for Convolution2D\n",
    "train_data = np.expand_dims(train_data,axis=3)\n",
    "test_data = np.expand_dims(test_data,axis=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517a1d4b",
   "metadata": {},
   "source": [
    "# Step 5\n",
    "Shuffle the training data and label together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675138c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "train_data, act_train_labels = shuffle(train_data, act_train_labels, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f14733c",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_train_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a28dba4",
   "metadata": {},
   "source": [
    "# Step 6\n",
    "Create a local directory to house the numpy arrays as write them out as binary objects to local disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae56ec8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to npy file\n",
    "!mkdir npydata\n",
    "save('npydata/train_data.npy', train_data)\n",
    "save('npydata/train_labels.npy', act_train_labels)\n",
    "save('npydata/test_data.npy', test_data)\n",
    "save('npydata/test_labels.npy', act_test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70d8e84",
   "metadata": {},
   "source": [
    "# Step 7\n",
    "Upload the npy arrays to S3 so SageMaker Training instances are able to read them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709fe8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name of the bucket\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "response = s3_client.upload_file('npydata/train_data.npy', data_bucket_name, 'train/train_data.npy')\n",
    "response = s3_client.upload_file('npydata/train_labels.npy', data_bucket_name, 'train/train_labels.npy')\n",
    "response = s3_client.upload_file('npydata/test_data.npy', data_bucket_name, 'test/test_data.npy')\n",
    "response = s3_client.upload_file('npydata/test_labels.npy', data_bucket_name, 'test/test_labels.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605490c3",
   "metadata": {},
   "source": [
    "# Step 8\n",
    "The next cell allows your S3 bucket name to be carried over into the training notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6071105b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store data_bucket_name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
